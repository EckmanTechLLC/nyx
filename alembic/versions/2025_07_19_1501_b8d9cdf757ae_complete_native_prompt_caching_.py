"""Complete native prompt caching implementation

Revision ID: b8d9cdf757ae
Revises: 9b55dec0a2cd
Create Date: 2025-07-19 15:01:45.833532

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = 'b8d9cdf757ae'
down_revision: Union[str, None] = '9b55dec0a2cd'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('llm_interactions', sa.Column('cached_token_count', sa.Integer(), nullable=True))
    op.add_column('llm_interactions', sa.Column('cache_creation_input_tokens', sa.Integer(), nullable=True))
    op.add_column('llm_interactions', sa.Column('cache_read_input_tokens', sa.Integer(), nullable=True))
    op.add_column('llm_interactions', sa.Column('cost_without_cache_usd', sa.DECIMAL(precision=10, scale=6), nullable=True))
    op.add_column('llm_interactions', sa.Column('uses_prompt_caching', sa.Boolean(), nullable=True))
    op.add_column('llm_interactions', sa.Column('cache_ttl_seconds', sa.Integer(), nullable=True))
    op.add_column('llm_interactions', sa.Column('cache_hit', sa.Boolean(), nullable=True))
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_column('llm_interactions', 'cache_hit')
    op.drop_column('llm_interactions', 'cache_ttl_seconds')
    op.drop_column('llm_interactions', 'uses_prompt_caching')
    op.drop_column('llm_interactions', 'cost_without_cache_usd')
    op.drop_column('llm_interactions', 'cache_read_input_tokens')
    op.drop_column('llm_interactions', 'cache_creation_input_tokens')
    op.drop_column('llm_interactions', 'cached_token_count')
    # ### end Alembic commands ###
